Hashing

Hash Table - 
	A collection of items which are stored in such a way as to 
	make it easy to find them later. Each position of the hash 
	table, often called a slot, can hold an item and is named by
	an integer value starting at 0. For example, we will have a 
	slot named 0, a slot named 1, a slot named 2, so on. Initially,
	the hash table contains no items so every slot is empty. We can
	implement a hash table by using a list with each element initialized
	to the special Python value None. 

Ex: hash table of size m = 11. There are m slots, named 0 through 10.

  0		1  	  2		3     4		5	  6		7	  8		9     10
[None][None][None][None][None][None][None][None][None][None][None]

The Hash Function - 
	The mapping between an item and the slot where the item belongs.

The hash function will take any item in the collection and return
an integer in the range of slot names, between 0 and m-1. Assume
that we have the set of int items 54, 26, 93, 17, 77, and 31. 
Our first hash function, referred to as the 'remainder method' 
simply takes an item and divides it by the table size, returning
the remainder as its hash value (h(item) = item % 11) 

	Simple Hash Function Using Remainders

Item		Hash Value

54			10
26			4
93			5
17			6
77			0	
31			9

Once the hash values have been computed, we can insert each item
into the hash table at the designated position. 

 0	  1		2 	  3		4  5   6	7	  8	   9   10
[77][None][None][None][26][93][17][None][None][31][54]

6 of the 11 slots are occupied, this is the load factor.
Load Factor:
	lambda = number of items / table size 
	lambda = 6 / 11

Now when we want to search for an item, we simply use the hash 
function to compute the slot name for the item and then check 
the hash table to see if it is present. This searching 
operations is O(1), since a constant amount of time is required to
compute the hash value and then index the hash table at that location.

Problem: This technique will only work if each item maps to a 
unique location in the hash table. For example, if the item 44 had 
been the next item, it would have a hash value of 0 (44%11==0). 
Since 77 also had a hash value of 0, it would be a problem. 
According the the hash function, two or more items would need to be
in the same slot. This is called a collision or clash. 

-----------------------------------------------------------------
Hash Functions

Perfect Hash Function - 
	Given a collection of items, a hash function that maps each
	item into a unique slot. 

One way to always have a perfect hash function is to increase the
size of the hash table so that each possible value in the item 
range can be accommodated. This guarantees that each item will
have a unique slot. Although this is practical for a small 
number of items, it is not feasible when the number of possible 
items is large. For example, if the items were nine-digit 
Social Security numbers, this method would require nearly 
one billion slots. 

-----------------------

Our goal is to create a hash table that minimizes the number of 
collisions, is easy to compute, and evenly distributes the items
in the hash table. 



1. Folding Method - 

		Begins by dividing the item into equal-size peices(the last
		peice may not be of equal size). These peices are then added
		together to give the resulting hash value. For example, if
		our item was the phone number 436-555-4601, we would take
		the digits and divide them into groups of 2 (43, 65, 55, 46, 01).
		After the addition, 43 + 65 + 55 + 46 + 01, we get 210. If
		we assume our hash table has 11 slots, then weneed to perform
		the extra step of dividing by 11 and keeping the remainder.
		In this case, 210 % 11 = 1, so the phone number hashes to
		slot 1. 
		Some folding methods go one step further and reverse every 
		other peice before the addition. For the above example, 
		we get 43 + 56 + 55 + 64 + 01 = 219. Which gives 219%11 = 10. 

2. Mid-Square Method - 

		We first square the item, then extract some portion of the
		resulting digits. For example, if the item were 44, 
		we would first compute 44**2 = 1,936. By extracting the
		middle two digit, 93, and performing the remainder step 
		93 % 11 = 5. 

			Comparison of Remainder and Mid-Square Methods

		Item		Remainder		Mid-Square

		54			10				3
		26			4				7
		93			5				9
		17			6				8
		77			0				4
		31			9				6


3. Ordinal Values - 

		We can create hash functions for character-based items
		such as strings. The word 'cat' can be thought of as
		a sequence of ordinal values.

		>>> ord('c')
		99
		>>> ord('a')
		97
		>>> ord('t')
		116

		We can then take these 3 ordinal values, add them up, and
		use the remainder method to get a hash value. 

		99 + 97 + 116 = 312
		312 % 11 = 4

		It is interesting to note that when using this hash 
		function, anagrams will always be given the same hash
		value. To remedy this, we could use the position of the
		characters as weight. 

		ex: 
				Position

			1 	2	3

			c	a	t

			ord('c') = 99
			ord('a') = 97
			ord('t') = 116

			99*1 + 97*2 + 116*3 = 641
			641 % 11 = 3

-------------------------------------------------------------------

Collision Resolution - 
	A systematic method for placing the second item in the hash
	table when two items has to the same slot. 

1. Open Addressing - 
		
		Attempts to find the next open slot or address in 
		hash table. 

		One method for resolving collisions looks into the hash
		table and tries to find another open slot to hold the item
		that caused the collision. A simple way to do this is
		to start at the original hash value position and then 
		move in a sequential manner through the slots until we 
		encounter the first slot that is empty. Note that we may
		need to go back to the first slot to cover the endsflktire 
		hash table. 

		Linear Probing - 
			Systematically visiting each slot one at a time. 

		Ex: when we attemp to place 44 in slot 0, a collison 
		occurs, under linear probing, we looking sequentially, 
		until we find an open position. Here it is slot 1. 

		 0	 1	 2 	 3   4   5	 6	  7		8	 9   10
		[77][44][55][20][26][93][17][None][None][31][54]

		Once we have built a hash table using open addressing and 
		linear probing, it is essential that we utilize the same
		methods to search for items. Assume we want to look up the
		item 93. When we compute the hash value, we get 5. Looking
		in slot 5 reveals 93, and we can return True. What if we are
		looking for 20? Now the hash is 9, and slot 9 is currently
		holding 31. We cannot simply return False since we know that
		there could have been collisions. We are now forced to do a
		sequential search, starting at position 10, looking until
		either we find the item 20 or we find an empty slot. 

		A disadvantage to linear probing is the tendency for 
		clustering. 
		Clustering - 
			Items become clustered in the table. 

		This means that if many collisions occur at the same hash
		value, a number of surrounding slots will be filled by the
		linear probing resolution. This will have an impact on 
		other items that are being inserted. 
			

		One way to deal with clustering is to extend the linear
		probing technique so that instead of looking sequentially
		for the next open slot, we skip slots, thereby more evenly
		distributing the items that have caused collisions. This 
		will potentially reduce the clustering that occurs. 

		ex: plus 3 probe

		 1	 2	  3	   4   5   6   7   8    9    10  11
		[77][55][None][44][26][93][17][20][None][31][54]

		Rehasing - 
			Process of looking for another slot after a collision. 

		With linear probing, the rehash function is:
		newhashvalue = rehash(oldhashvalue) where
		rehash(pos)= (pos + 1) % sizeoftable. 

		The 'plus 3' rehash can be defined as:
		rehash(pos) = (pos + 3) % sizeoftable

		In general:
		rehash(pos) = (pos + skip) % sizeoftable

		It is important to note that the size of the 'skip' must
		be such that all the slots in the table will eventually be
		visited. Otherwise, part of the table will be unused. To
		ensure this, it is suggested that the table size be a 
		prime number. 

		-------------------------
		Quadratic probing - 
			Instead of using a constant 'skip' value, we use a 
			rehash function that increments the hash value by 
			1, 3, 5, 7, 9, and so on. This means that if the 
			first value is h, the successive valuse are
			h+1, h+4, h+9, h+16, and so on. Quadratic probing
			uses a skip consiting of perfect squares. 

			 0	 1	 2 	 3	 4	 5	 6	  7	 	8 	 9	 10
			[77][44][20][55][26][93][17][None][None][31][54]


		Chaining - 
			An alternative method for handling the collision problem
			is to allow each slot to hold a reference to a collection
			(or chain) of items. Chaining allows many items to exist
			at the same location in the hash table. When collisions
			happen, the item is still placed in the proper slot of
			the hash table. As more and more items hash to the same
			location, the difficulty of searching for the item in
			the collection increases. 
	
			1	2	  3		4	5 6 7	8	  9	  10 11
			[][None][None][None][][][][None][None][][]
			
			[77]			   [26][93][17]	      [31][54]
			[44]								  [20]
			[55]

Collision Resolution with Chaining:

When we want to search for an item, we use the hash function to 
generate the slot where it should reside. Since each slot holds a 
collection, we use a searching technique to decide whether the item
is present. The advantage is that on average, there are likely to
be many fewer items in each slot, so there is could be more 
efficient. 

	
-----------------------------------------------------------------
Analysis of Hashing

In the best case, hashing would provide a O(1), constant time search
technique. The most important piece of info to analyze the use of
a hash table is the load factor, lambda. Conceptually, if lambda, 
or the load factor, is small, then there is a lower chance of 
collisions, meaning that items are more likely to be in the slots
where they belong. If lambda is large, meaning that the table is
filling up, then there are more and more collisions. This means
that collision resolution is more difficult, requiring more 
comparisons to find an empy slot. With chaining, increased 
collisions means an incrased number of items on each chain. 

For a successful search using open addressing with linear
probing, the avg number of comparisions is approximatately
1/2 * [ 1 + (1 / (1 - lambda))] 

An unsucessful search gives:
1/2 * [ 1 + (1 / (1 - lambda))**2). 

Using chaining, 
succsesfull: the avg number of comparisons is:
1 + (lambda / 2)

unsuccsefful: 
lambda
